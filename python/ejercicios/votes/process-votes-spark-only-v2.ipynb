{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesado de votos con join en Spark\n",
    "\n",
    "Este notebook es una alternativa a `process-votes-with-KSQL`. En este caso leeremos la tabla de municipios directamente en Spark, en vez de depender del preprocesado con Connect y KSQL. Este notebook simplemente incluye el join y la consulta del dashboard principal. El otro notebook incluye consultas intermedias para practicar con el procesado de streams en spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import from_json\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as fn\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "PACKAGES = \"org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.0,org.xerial:sqlite-jdbc:3.27.2\"\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"StructuredVotesSparkOnly\") \\\n",
    "    .config(\"spark.jars.packages\", PACKAGES)\\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ejercicios.votes import TOPIC_VOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La lectura desde un SQL en Spark es tan sencilla como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = {'driver': 'org.sqlite.JDBC', 'date_string_format': 'yyyy-MM-dd HH:mm:ss'}\n",
    "municipios = spark.read.jdbc(\"jdbc:sqlite:/tmp/municipios.db\", \"municipios\", properties=properties) \\\n",
    "    .withColumnRenamed('Codigo', 'CODIGO') \\\n",
    "    .withColumnRenamed('Comunidad', 'COMUNIDAD') \\\n",
    "    .withColumnRenamed('Provincia', 'PROVINCIA') \\\n",
    "    .withColumnRenamed('Municipio', 'MUNICIPIO') \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipios.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipios.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora leemos el topic de VOTES, en vez de VOTES_ENRICHED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "  .option(\"startingOffsets\", \"earliest\") \\\n",
    "  .option(\"subscribe\", TOPIC_VOTES) \\\n",
    "  .load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mensajes llegan en formato JSON, pero al contrario que con `spark.read.csv`, debemos indicar el esquema completo (OJO, este esquema sólo tiene CODIGO y PARTIDO porque el topic VOTES aún no se ha combinado con la tabla estática)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"Codigo\", IntegerType()),\n",
    "    StructField(\"Partido\", StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de verificación de firma V2 descarga los votos que provienen de Andalucía. Podríamos añadir más criterios si fuera necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_signature(comunidad, provincia, municipio):\n",
    "    if 'And' not in comunidad:\n",
    "        return 'OK'\n",
    "\n",
    "udf_process_signature = fn.udf(process_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente construimos la query de procesado de votos. Si la comparamos con la query del primer notebook, ésta sólo incluye las transformaciones `join` y `withColumnRenamed` (para evita cambiar el resto del código)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = df \\\n",
    "    .selectExpr(\"topic\", \"CAST(key AS STRING)\", \"CAST(value AS STRING) AS value\") \\\n",
    "    .withColumn(\"value_json\", fn.from_json(col('value'), schema)) \\\n",
    "    .select('value_json.Codigo', 'value_json.Partido') \\\n",
    "    .withColumnRenamed('Codigo', 'CODIGO') \\\n",
    "    .withColumnRenamed('Partido', 'PARTIDO') \\\n",
    "    .join(municipios, 'CODIGO', 'inner') \\\n",
    "    .withColumn('SIGNATURE', udf_process_signature(col('COMUNIDAD'), col('PROVINCIA'), col('MUNICIPIO'))) \\\n",
    "    .where(~ fn.isnull(col('SIGNATURE'))) \\\n",
    "    .groupBy('COMUNIDAD', 'PROVINCIA', 'PARTIDO') \\\n",
    "    .agg(fn.count('*').alias('VOTOS')) \\\n",
    "    .sort(col('COMUNIDAD').asc(), col('PROVINCIA').asc(), col('VOTOS').desc()) \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName('dashboard') \\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y leemos el dashboard igual que en el otro notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT COMUNIDAD, PARTIDO, sum(VOTOS) as VOTOS\n",
    "  FROM dashboard\n",
    "  WHERE VOTOS > 2 and COMUNIDAD LIKE 'And%'\n",
    "  GROUP BY COMUNIDAD, PARTIDO\n",
    "  ORDER BY VOTOS DESC\n",
    "\"\"\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
