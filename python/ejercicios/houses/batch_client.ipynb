{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cliente de la rama BATCH\n",
    "\n",
    "Este cliente se limita a leer los datos del topic y los vuelca al fichero historic.csv. Podríamos tener varios procesos iguales para permitir alta disponibilidad y mejor rendimiento, pero:\n",
    "- deberíamos asegurarnos de que varios procesos pueden escribir a la vez en el fichero,\n",
    "- en este caso particular (que no deja de ser un ejemplo muy sintético) incluso aunque el topic esté formado por varias particiones para facilitar el trabajo de la rama real-time, este cliente tan ligero que probablemente añadir varios no mejore el rendimiento.\n",
    "\n",
    "Si el destino fuera una base de datos probablemente podríamos obviar la primera consideración, aunque en el mundo streaming es más habitual volcar los datos a HDFS o S3. Recordemos que la escritura en HDFS en procesos Hadoop ocurre independientemente en cada tarea _reducer_ para conseguir paralelizar. Para paralelizar en streaming podemos buscar un efecto parecido: si tenemos varias particiones con un cliente por partición, la escritura de los clientes puede ser independiente si escriben en HDFS o en S3. En este caso perdemos el orden de los datos: los datos escritos en un mismo fichero por un mismo cliente sí pueden mantener el orden, pero de un fichero a otro no es posible. Una manera de solventar esto es escribir los ficheros en carpetas separadas por bloques de horas, además de que cada registro esté identificado por un timestamp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ejercicios.houses import BATCH_GROUP, HISTORIC, TOPIC_SALES\n",
    "\n",
    "ds = pd.read_csv(HISTORIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, KafkaError\n",
    "import json\n",
    "\n",
    "c = Consumer({\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': BATCH_GROUP,\n",
    "    'auto.offset.reset': 'earliest'\n",
    "})\n",
    "\n",
    "c.subscribe([TOPIC_SALES])\n",
    "\n",
    "while True:\n",
    "    msg = c.poll(1.0)\n",
    "\n",
    "    if msg is None:\n",
    "        continue\n",
    "    if msg.error():\n",
    "        print(\"Consumer error: {}\".format(msg.error()))\n",
    "        continue\n",
    "\n",
    "    data_json = msg.value().decode('utf-8')\n",
    "    data_dict = json.loads(data_json)\n",
    "\n",
    "    print('Received message: {}:{}'.format(data_dict.get('price'), data_dict.get('yr_built')))\n",
    "\n",
    "    ds = ds.append(data_dict, ignore_index=True)\n",
    "    ds.to_csv(HISTORIC)\n",
    "\n",
    "c.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
